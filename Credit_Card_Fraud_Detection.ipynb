{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Iu4faRK9T_6p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # data processing\n",
        "import numpy as np # working with arrays\n",
        "import matplotlib.pyplot as plt # visualization\n",
        "from termcolor import colored as cl # text customization\n",
        "import itertools # advanced tools\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler # data normalization\n",
        "from sklearn.model_selection import train_test_split # data split\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision tree algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN algorithm\n",
        "from sklearn.linear_model import LogisticRegression # Logistic regression algorithm\n",
        "from sklearn.svm import SVC # SVM algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm\n",
        "from xgboost import XGBClassifier # XGBoost algorithm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix # evaluation metric\n",
        "from sklearn.metrics import accuracy_score # evaluation metric\n",
        "from sklearn.metrics import f1_score # evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING DATA\n",
        "\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "df.drop('Time', axis = 1, inplace = True)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "FseRi6RnUFgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c7c489-9160-4643-c6a4-35c19609c1af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
            "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
            "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
            "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
            "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
            "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
            "\n",
            "        V25       V26       V27       V28  Amount  Class  \n",
            "0  0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
            "1  0.167170  0.125895 -0.008983  0.014724    2.69    0.0  \n",
            "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
            "3  0.647376 -0.221929  0.062723  0.061458  123.50    0.0  \n",
            "4 -0.206010  0.502292  0.219422  0.215153   69.99    0.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cases = len(df)\n",
        "nonfraud_count = len(df[df.Class == 0])\n",
        "fraud_count = len(df[df.Class == 1])\n",
        "fraud_percentage = round(fraud_count/nonfraud_count*100, 2)\n",
        "\n",
        "print(cl('CASE COUNT', attrs = ['bold']))\n",
        "print(cl('--------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Total number of cases are {}'.format(cases), attrs = ['bold']))\n",
        "print(cl('Number of Non-fraud cases are {}'.format(nonfraud_count), attrs = ['bold']))\n",
        "print(cl('Number of fraud cases are {}'.format(fraud_count), attrs = ['bold']))\n",
        "print(cl('Percentage of fraud cases is {}'.format(fraud_percentage), attrs = ['bold']))\n",
        "print(cl('--------------------------------------------', attrs = ['bold']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3LKRcsLnV0H",
        "outputId": "0a7268ff-d7d1-41e4-c409-ef61fe0d551d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCASE COUNT\u001b[0m\n",
            "\u001b[1m--------------------------------------------\u001b[0m\n",
            "\u001b[1mTotal number of cases are 7973\u001b[0m\n",
            "\u001b[1mNumber of Non-fraud cases are 7947\u001b[0m\n",
            "\u001b[1mNumber of fraud cases are 25\u001b[0m\n",
            "\u001b[1mPercentage of fraud cases is 0.31\u001b[0m\n",
            "\u001b[1m--------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonfraud_cases = df[df.Class == 0]\n",
        "fraud_cases = df[df.Class == 1]\n",
        "\n",
        "print(cl('CASE AMOUNT STATISTICS', attrs = ['bold']))\n",
        "print(cl('--------------------------------------------', attrs = ['bold']))\n",
        "print(cl('NON-FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
        "print(nonfraud_cases.Amount.describe())\n",
        "print(cl('--------------------------------------------', attrs = ['bold']))\n",
        "print(cl('FRAUD CASE AMOUNT STATS', attrs = ['bold']))\n",
        "print(fraud_cases.Amount.describe())\n",
        "print(cl('--------------------------------------------', attrs = ['bold']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10_SpxO1nZO_",
        "outputId": "abfe841a-1825-4e5c-8aa9-21d5f18c2a0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mCASE AMOUNT STATISTICS\u001b[0m\n",
            "\u001b[1m--------------------------------------------\u001b[0m\n",
            "\u001b[1mNON-FRAUD CASE AMOUNT STATS\u001b[0m\n",
            "count    7947.000000\n",
            "mean       65.284891\n",
            "std       194.126547\n",
            "min         0.000000\n",
            "25%         4.795000\n",
            "50%        15.950000\n",
            "75%        54.990000\n",
            "max      7712.430000\n",
            "Name: Amount, dtype: float64\n",
            "\u001b[1m--------------------------------------------\u001b[0m\n",
            "\u001b[1mFRAUD CASE AMOUNT STATS\u001b[0m\n",
            "count      25.000000\n",
            "mean      106.308400\n",
            "std       372.676883\n",
            "min         0.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         1.000000\n",
            "max      1809.680000\n",
            "Name: Amount, dtype: float64\n",
            "\u001b[1m--------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "amount = df['Amount'].values\n",
        "\n",
        "df['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
        "\n",
        "print(cl(df['Amount'].head(10), attrs = ['bold']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsmXje_Yo4aC",
        "outputId": "da39f9d0-186c-4a8a-8863-e8402c97909d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m0    0.432052\n",
            "1   -0.321826\n",
            "2    1.607225\n",
            "3    0.298034\n",
            "4    0.023481\n",
            "5   -0.316798\n",
            "6   -0.310025\n",
            "7   -0.126289\n",
            "8    0.142569\n",
            "9   -0.316746\n",
            "Name: Amount, dtype: float64\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA SPLIT\n",
        "\n",
        "X = df.drop('Class', axis = 1).values\n",
        "y = df['Class'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(cl('X_train samples : ', attrs = ['bold']), X_train[:1])\n",
        "print(cl('X_test samples : ', attrs = ['bold']), X_test[0:1])\n",
        "print(cl('y_train samples : ', attrs = ['bold']), y_train[0:20])\n",
        "print(cl('y_test samples : ', attrs = ['bold']), y_test[0:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2drwdoDpBHz",
        "outputId": "8a32cfa7-d44a-4680-e7de-b9c9eef312aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mX_train samples : \u001b[0m [[-0.25996089  0.99864579  1.43797463  0.03803135  0.12540526 -0.95777536\n",
            "   0.8997578  -0.2701587  -0.18683424 -0.29150297 -0.19125424 -0.391187\n",
            "  -0.32325761 -0.55428413  0.97013337  0.31980038 -0.07146977 -0.11304597\n",
            "  -0.08589306  0.17163495 -0.31653484 -0.69753402 -0.03522758  0.32238743\n",
            "  -0.19879657  0.04462992  0.07731771 -0.12513487 -0.28980937]]\n",
            "\u001b[1mX_test samples : \u001b[0m [[-0.6579584   1.18973437  1.44659568  1.04472058 -0.2436541  -0.59687647\n",
            "   0.68080456 -0.17278975  1.14924165 -0.19329017  0.29748074 -3.29912945\n",
            "   0.33252864  1.8908937   0.58290063 -0.11719044  0.54107169  0.3504831\n",
            "   0.29766467 -0.05900805 -0.2991929  -0.60075936  0.1565226   0.25120609\n",
            "  -0.5847546  -0.67589705  0.14453086  0.2296527  -0.07872562]]\n",
            "\u001b[1my_train samples : \u001b[0m [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[1my_test samples : \u001b[0m [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELING\n",
        "\n",
        "# 1. Decision Tree\n",
        "\n",
        "#np.nan_to_num(X_test)\n",
        "tree_model = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_yhat = tree_model.predict(X_test)\n",
        "\n",
        "# 2. K-Nearest Neighbors\n",
        "\n",
        "n = 5\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = n)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_yhat = knn.predict(X_test)\n",
        "\n",
        "# 3. Logistic Regression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_yhat = lr.predict(X_test)\n",
        "\n",
        "# 4. SVM \n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_yhat = svm.predict(X_test)\n",
        "\n",
        "# 5. Random Forest Tree\n",
        "\n",
        "rf = RandomForestClassifier(max_depth = 4)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_yhat = rf.predict(X_test)\n",
        "\n",
        "# 6. XGBoost\n",
        "\n",
        "xgb = XGBClassifier(max_depth = 4)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_yhat = xgb.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "JY0CL8E8pIIK",
        "outputId": "86902a87-98c3-44f7-fa23-6f692f279e95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0152d785b2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtree_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 2. K-Nearest Neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             if issparse(X) and (\n\u001b[1;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Accuracy score\n",
        "\n",
        "print(cl('ACCURACY SCORE', attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test, tree_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the KNN model is {}'.format(accuracy_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the SVM model is {}'.format(accuracy_score(y_test, svm_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the Random Forest Tree model is {}'.format(accuracy_score(y_test, rf_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n"
      ],
      "metadata": {
        "id": "RGV59UzFpJNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. F1 score\n",
        "\n",
        "print(cl('F1 SCORE', attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the Decision Tree model is {}'.format(f1_score(y_test, tree_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the KNN model is {}'.format(f1_score(y_test, knn_yhat)), attrs = ['bold'], color = 'green'))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test, lr_yhat)), attrs = ['bold'], color = 'red'))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the SVM model is {}'.format(f1_score(y_test, svm_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the Random Forest Tree model is {}'.format(f1_score(y_test, rf_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n",
        "print(cl('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_yhat)), attrs = ['bold']))\n",
        "print(cl('------------------------------------------------------------------------', attrs = ['bold']))\n"
      ],
      "metadata": {
        "id": "uxAJH58epM5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Confusion Matrix\n",
        "\n",
        "# defining the plot function\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title, normalize = False, cmap = plt.cm.Blues):\n",
        "    title = 'Confusion Matrix of {}'.format(title)\n",
        "    if normalize:\n",
        "        cm = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation = 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment = 'center',\n",
        "                 color = 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Compute confusion matrix for the models\n",
        "\n",
        "tree_matrix = confusion_matrix(y_test, tree_yhat, labels = [0, 1]) # Decision Tree\n",
        "knn_matrix = confusion_matrix(y_test, knn_yhat, labels = [0, 1]) # K-Nearest Neighbors\n",
        "lr_matrix = confusion_matrix(y_test, lr_yhat, labels = [0, 1]) # Logistic Regression\n",
        "svm_matrix = confusion_matrix(y_test, svm_yhat, labels = [0, 1]) # Support Vector Machine\n",
        "rf_matrix = confusion_matrix(y_test, rf_yhat, labels = [0, 1]) # Random Forest Tree\n",
        "xgb_matrix = confusion_matrix(y_test, xgb_yhat, labels = [0, 1]) # XGBoost\n",
        "\n",
        "# Plot the confusion matrix\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6, 6)\n",
        "\n",
        "# 1. Decision tree\n",
        "\n",
        "tree_cm_plot = plot_confusion_matrix(tree_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'Decision Tree')\n",
        "plt.savefig('tree_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 2. K-Nearest Neighbors\n",
        "\n",
        "knn_cm_plot = plot_confusion_matrix(knn_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'KNN')\n",
        "plt.savefig('knn_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 3. Logistic regression\n",
        "\n",
        "lr_cm_plot = plot_confusion_matrix(lr_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'Logistic Regression')\n",
        "plt.savefig('lr_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 4. Support Vector Machine\n",
        "\n",
        "svm_cm_plot = plot_confusion_matrix(svm_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'SVM')\n",
        "plt.savefig('svm_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 5. Random forest tree\n",
        "\n",
        "rf_cm_plot = plot_confusion_matrix(rf_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'Random Forest Tree')\n",
        "plt.savefig('rf_cm_plot.png')\n",
        "plt.show()\n",
        "\n",
        "# 6. XGBoost\n",
        "\n",
        "xgb_cm_plot = plot_confusion_matrix(xgb_matrix, \n",
        "                                classes = ['Non-Default(0)','Default(1)'], \n",
        "                                normalize = False, title = 'XGBoost')\n",
        "plt.savefig('xgb_cm_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZRnlNpK5pQWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}